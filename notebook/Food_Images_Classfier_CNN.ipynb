{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import HDF5Matrix \n",
    "import h5py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f= h5py.File('Train/food_c101_n1000_r384x384x3.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=HDF5Matrix('Train/food_c101_n10099_r32x32x1.h5','images')\n",
    "ytrain=HDF5Matrix('Train/food_c101_n10099_r32x32x1.h5','category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('xtrain shape is: ',xtrain.shape,', ytrain shape is: ',ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain=np.asarray(xtrain,dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain=np.asarray(ytrain,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtest=HDF5Matrix('Test/food_test_c101_n1000_r32x32x1.h5','images')\n",
    "ytest=HDF5Matrix('Test/food_test_c101_n1000_r32x32x1.h5','category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('xtest shape is: ',xtest.shape,', ytest shape is: ',ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest=np.asarray(xtest,dtype='float32')\n",
    "ytest=np.asarray(ytest,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels =f.get('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[:][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header=np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_names =f.get('category_names')\n",
    "category_names=np.array(category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "category_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain_scaled=xtrain/255\n",
    "xtest_scaled=xtest/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_encoded=to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_encoded=labels_encoded.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_encoded.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_channel=1\n",
    "n_width=32\n",
    "n_heght=32\n",
    "n_output=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_variable(channel,width,height,output):\n",
    "    X=tf.placeholder(tf.float32,shape=[None,height,width,channel],name='Input')\n",
    "    Y=tf.placeholder(tf.float32,shape=[None,output],name='output')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_variable():\n",
    "    W1=tf.get_variable(\"W1\",[4,4,1,8],tf.float32,tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2=tf.get_variable(\"W2\",[4,4,8,16],tf.float32,tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    return W1,W2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create mini-batch\n",
    "\n",
    "def mini_batch(xdata,ydata,batch_size):\n",
    "    x_size=xdata.shape[0]\n",
    "    y_size=ydata.shape[0]\n",
    "    for i in range(0,x_size,batch_size):\n",
    "        yield xdata[i:i+batch_size],ydata[i:i+batch_size]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_layer(W1,W2,X,Y):\n",
    "    #W1,W2=initialize_variable()\n",
    "    #X,Y=create_variable(channel,width,height,output)\n",
    "    conv1=tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding='SAME')\n",
    "    max_pool1=tf.nn.max_pool(tf.nn.relu(conv1),ksize=[1,2,2,1],strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    conv2=tf.nn.conv2d(max_pool1,W2,strides=[1,2,2,1],padding='SAME')\n",
    "    max_pool2=tf.nn.max_pool(tf.nn.relu(conv2),ksize=[1,4,4,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    max_pool2=tf.contrib.layers.flatten(max_pool2)\n",
    "    out=tf.contrib.layers.fully_connected(max_pool2,n_output,activation_fn=None)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(out,Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out,labels=Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    learning_rate=0.05\n",
    "    tf.reset_default_graph()\n",
    "    #tf.get_default_graph()\n",
    "    \n",
    "    xtrain_initialiazer=tf.placeholder(dtype=xtrain.dtype,shape=xtrain.shape)\n",
    "    ytrain_initialiazer=tf.placeholder(dtype=ytrain.dtype,shape=ytrain.shape)\n",
    "    \n",
    "    xtrain_input=tf.Variable(xtrain_initialiazer,trainable=False,collections=[])\n",
    "    ytrain_input=tf.Variable(ytrain_initialiazer,trainable=False,collections=[])\n",
    "    \n",
    "    images,labels=tf.train.slice_input_producer([xtrain_input,ytrain_input],num_epochs=2)\n",
    "    labels=tf.cast(labels,tf.float32)\n",
    "    \n",
    "    images,labels=tf.train.batch([images,labels],batch_size=128)\n",
    "    \n",
    "    \n",
    "    #x,y=create_variable(n_channel,n_width,n_heght,n_output)\n",
    "    W1,W2=initialize_variable()\n",
    "    out = create_layer(W1,W2,images,labels)\n",
    "    loss=compute_cost(out,labels)\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    #accuracy\n",
    "    \n",
    "    \n",
    "    init_op=tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        sess.run(xtrain_input.initializer,feed_dict={xtrain_initialiazer:xtrain_scaled})\n",
    "        sess.run(ytrain_input.initializer,feed_dict={ytrain_initialiazer:ytrain})\n",
    "        \n",
    "            \n",
    "        #start the enque thread\n",
    "        coord=tf.train.Coordinator()\n",
    "        threads=tf.train.start_queue_runners(sess,coord=coord)\n",
    "        while not coord.should_stop() :\n",
    "            \n",
    "            opt,cost=sess.run([optimizer,loss])   \n",
    "        #coord.request_stop()\n",
    "        correct_pred=tf.equal(tf.argmax(out,axis=1),tf.argmax(labels,axis=1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "        print('accuracy',accuracy)\n",
    "        print(\"Test accuracy\",accuracy.eval())\n",
    "    return opt,cost\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(xtrain_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
